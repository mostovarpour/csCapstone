<h3 id="project-overview">Project Overview</h2>
<p>
    With continued advances in space exploration, the need to efficiently process the large quantity of data received from space continues to grow exponentially. One important piece of data is the massive images of other planets, usually several thousand to several million pixels in size. The current methods of viewing these images is by either building pyramids or by creating tiles which can often take anywhere from a few minutes to a few days.  Building pyramids also consumes a massive amount of disk space. We plan to provide researchers with a method of quickly viewing these images and a tool in which to view the images. The method we will provide is a stochastic sampling algorithm and the tool will be a lightweight image viewer. Our image sampling method, combined with our image viewer, will provide researchers the ability to view these massive images in a manner of minutes instead of hours.
</p>
<img style="width: 500px; height: 275px;" src="images/best.png"/>
<img style="width: 30px;" src="images/arrowright.png"/>
<img style="width: 250px; height: 150px;" src="images/best.png"/> 
<p>
    The full size image can be anywhere from a few megabytes all the way up to terabytes.
    The larger the image, the longer it will take to downsample the image
</p>
<h3 id="implementation-overview">Implementation Overview</h3>
<p>
    We implemented our image reader inside of an existing open source library called GDAL.
    GDAL stands for the Geospatial Data Abstraction Library, and it handles file reading
    and writing for many image formats. In order to render the image, we created a simple
    interface using OpenGL, GLFW3, and GLEW.
</p>
<h3 id="implementation">Implementation</h3>
<p>
    After many failed attempts at implementing a stochastic sampling algorithm that actually
    runs as fast as we needed it to, we finally came to the conclusion that as long as we're
    using GDAL we couldn't do much to make it faster. The way GDAL reads images is by reading chunks at a time.
    So anytime we want to get any one pixel, we have to read a whole portion of the image first.
    To solve this problem, we determined the only way to improve the speed is make less of these
    read calls. By doing this, we were able to improve the speed of processing the image, however we
    do lose substantial quality. In order to give our users more control over this, we added
    an extra parameter that our algorithm takes that allows users to specify how much of the file 
    to read. This parameter makes the algorithm read a factor of the image. A parameter of 2
    will read half of the image, 3 will read 1/3, 4 reads 1/4, and so on. 
</p>
<img style="width: 60%;" src="images/stochasticGridCropped.png"/>
<p>
    This image represents how our algorithm works. Consider each cell
    in this grid is a section of the image that GDAL will read. Each black dot
    represents a pixel that our algorithm has sampled. The algorithm will run
    through the entire image skipped sections as needed. The number of sections skipped
    depends on the parameter that the user passes in. Once the end of the image is reached,
    any areas that it did not get any data for will automatically be filled in with the nearest pixel
    above it.
</p>

<h3 id="results">Results</h3>
<p>
    After finishing our downsampling algorithm, we tested it against another algorithm that
    already exists in GDAL called the nearest neighbor algorithm. In this algorithm, there is a set number
    of pixels read throughout the image.
</p>
<img style="width: 60%;" src="images/nearesetNeighborGridCropped.png"/>
<p>
    This image represents the nearest neighbor algorithm. This algorithm will
    read evenly spaced sections and evenly spaced pixels from those sections. The number of sections
    read depends on the size of the output. It will read enough data to fully fill the window.
</p>
<h4 id="test1">Test 1</h4>
<img style="width:49%;" src="images/LROC2.png"/>
<img style="width:49%;" src="images/lrocfull.png"/>
<p style="width: 49%; display:inline-block;" class="text-center">Stochastic Algorithm - Factor 2</p>
<p style="width: 49%; display:inline-block;" class="text-center">Nearest Neighbor Algorithm</p>
<div class="text-center">
    <img style="width:60%;" src="images/LROC_Results.png"/>
</div>
<h5>Results</h5>
<p>
    In this test, the stochastic algorithm was run with a factor of 2, this means
    that roughly half of the image was read. This makes the image load in about half the time
    that nearest neighbor runs
</p>
<h4 id="test2">Test 2</h4>
<img style="width:49%;" src="images/kaguya10.png"/>
<img style="width:49%;" src="images/kaguyafull.png"/>
<p style="width: 49%; display:inline-block;" class="text-center">Stochastic Algorithm - Factor 10</p>
<p style="width: 49%; display:inline-block;" class="text-center">Nearest Neighbor Algorithm</p>
<div class="text-center">
    <img style="width:60%;" src="images/Kaguya_Results.png"/>
</div>
<h5>Results</h5>
<p>
    In this test, the stochastic algorithm was run with a factor of 10, so roughly 
    1/10 of the image was read. This makes the image load that much faster.
</p>
<h3 id="Viewer">Image Viewer</h3>
<p>
    In order to really utilize this extra parameter. We added a feature to our image viewer 
    that progressively improves the image quality by updating the sampling parameter.
</p>
<img style="width: 60%;" src="images/progressive.gif"/>
<p>Animation shows progressive quality improvement</p>
<h3 id="conclusion">Conclusion</h3>
<p>
    In conclusion, this project has taken a different course than what we originally expected.
    In order to make the images load faster while still using GDAL, we had to limit
    the amount of image reading that was actually done. This technique can be applied to 
    nearly any type of algorithm in order to improve its speed at the cost of image quality.
    However, it may also be used to progressively load an image. By skipping portions of an image, 
    it may be pulled up faster, and the rest of the image can be loaded as time goes on.
</p>
<p>
    By implementing this algorithm inside of GDAL, it may become accessible to anyone in industry
    that is currently using the library. Our code is also open source and hosted on github so anyone
    may view it and expand on it.
</p>
